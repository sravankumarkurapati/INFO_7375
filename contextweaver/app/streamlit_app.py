# app/streamlit_app.py
import streamlit as st
import sys
from pathlib import Path
import plotly.graph_objects as go
import json
from datetime import datetime
import time

sys.path.append(str(Path(__file__).parent.parent / 'src'))

from contextweaver_pipeline import ContextWeaverPipeline
from config import Config
from langchain_core.documents import Document

# ==================== HELPER FUNCTIONS ====================
def make_serializable(obj):
    """Make object JSON serializable"""
    if isinstance(obj, dict):
        return {k: make_serializable(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [make_serializable(item) for item in obj]
    elif isinstance(obj, Document):
        return {
            'content': obj.page_content[:200],
            'metadata': {k: v for k, v in obj.metadata.items() if isinstance(v, (str, int, float, bool)) or v is None}
        }
    elif hasattr(obj, '__dict__'):
        return str(obj)
    else:
        return obj

# ==================== PAGE CONFIG ====================
st.set_page_config(
    page_title="ContextWeaver - Advanced AI Reasoning",
    page_icon="üß†",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==================== ENHANCED CSS WITH ANIMATIONS ====================
st.markdown("""
<style>
    /* Headers */
    .main-header {
        font-size: 4rem;
        font-weight: 900;
        text-align: center;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 50%, #f093fb 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
        padding: 2rem 0 0.5rem 0;
        letter-spacing: -2px;
    }
    
    .sub-header {
        text-align: center;
        font-size: 1.4rem;
        color: #4a5568;
        font-weight: 400;
        margin-bottom: 2rem;
    }
    
    /* Badges */
    .component-badge, .innovation-badge {
        display: inline-block;
        padding: 0.6rem 1.3rem;
        border-radius: 25px;
        font-size: 0.95rem;
        font-weight: 700;
        margin: 0.4rem;
        box-shadow: 0 4px 12px rgba(0,0,0,0.15);
        color: #ffffff;
        text-shadow: 0 1px 2px rgba(0,0,0,0.2);
    }
    
    .component-badge {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    }
    
    .innovation-badge {
        background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
        animation: glow 2s ease-in-out infinite;
    }
    
    @keyframes glow {
        0%, 100% { box-shadow: 0 4px 12px rgba(245, 87, 108, 0.4); }
        50% { box-shadow: 0 4px 20px rgba(245, 87, 108, 0.7); }
    }
    
    /* Source boxes - readable colors */
    .source-local {
        background: linear-gradient(135deg, #e8f5e9 0%, #c8e6c9 100%);
        border-left: 5px solid #2e7d32;
        padding: 1.8rem;
        border-radius: 12px;
        box-shadow: 0 4px 12px rgba(0,0,0,0.08);
    }
    
    .source-local h2 {
        color: #1b5e20;
        margin: 0 0 0.5rem 0;
    }
    
    .source-local p {
        color: #2e7d32;
        margin: 0.3rem 0;
    }
    
    .source-web {
        background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%);
        border-left: 5px solid #1565c0;
        padding: 1.8rem;
        border-radius: 12px;
        box-shadow: 0 4px 12px rgba(0,0,0,0.08);
    }
    
    .source-web h2 {
        color: #0d47a1;
        margin: 0 0 0.5rem 0;
    }
    
    .source-web p {
        color: #1565c0;
        margin: 0.3rem 0;
    }
    
    .source-llm {
        background: linear-gradient(135deg, #fff8e1 0%, #ffecb3 100%);
        border-left: 5px solid #f57c00;
        padding: 1.8rem;
        border-radius: 12px;
        box-shadow: 0 4px 12px rgba(0,0,0,0.08);
    }
    
    .source-llm h2 {
        color: #e65100;
        margin: 0 0 0.5rem 0;
    }
    
    .source-llm p {
        color: #f57c00;
        margin: 0.3rem 0;
    }
    
    /* Pipeline step indicators with animation */
    .pipeline-step {
        background: #f8f9fa;
        border: 2px solid #dee2e6;
        border-radius: 10px;
        padding: 1.2rem;
        margin: 0.6rem 0;
        color: #495057;
        transition: all 0.3s ease;
    }
    
    .pipeline-step.pending {
        background: #f8f9fa;
        border-color: #dee2e6;
        opacity: 0.6;
    }
    
    .pipeline-step.processing {
        background: linear-gradient(135deg, #fff3cd 0%, #ffe69c 100%);
        border-color: #ffc107;
        color: #856404;
        font-weight: 600;
        animation: pulse-processing 1s ease-in-out infinite;
    }
    
    .pipeline-step.complete {
        background: linear-gradient(135deg, #d4edda 0%, #a3d9a5 100%);
        border-color: #28a745;
        color: #155724;
        font-weight: 600;
    }
    
    .pipeline-step.disabled {
        background: #e9ecef;
        border-color: #adb5bd;
        color: #6c757d;
        opacity: 0.5;
    }
    
    @keyframes pulse-processing {
        0%, 100% { transform: scale(1); box-shadow: 0 2px 8px rgba(255, 193, 7, 0.3); }
        50% { transform: scale(1.02); box-shadow: 0 4px 16px rgba(255, 193, 7, 0.5); }
    }
    
    /* Metric cards */
    .metric-card {
        background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        padding: 1.5rem;
        border-radius: 12px;
        border-left: 6px solid #667eea;
        margin: 1rem 0;
        box-shadow: 0 4px 8px rgba(0,0,0,0.06);
    }
    
    .metric-card h4 {
        color: #2c3e50;
        margin: 0 0 0.8rem 0;
    }
    
    .metric-card p {
        color: #34495e;
        margin: 0.2rem 0;
    }
    
    /* Source item styling */
    .source-item-web, .source-item-local {
        padding: 0.9rem;
        margin: 0.5rem 0;
        background: #ffffff;
        border-radius: 10px;
        box-shadow: 0 2px 8px rgba(0,0,0,0.08);
        transition: transform 0.2s, box-shadow 0.2s;
    }
    
    .source-item-web:hover, .source-item-local:hover {
        transform: translateX(5px);
        box-shadow: 0 4px 12px rgba(0,0,0,0.12);
    }
    
    .source-item-web {
        border-left: 4px solid #1976d2;
    }
    
    .source-item-web strong {
        color: #0d47a1;
    }
    
    .source-item-local {
        border-left: 4px solid #388e3c;
    }
    
    .source-item-local strong {
        color: #1b5e20;
    }
    
    .source-badge {
        float: right;
        padding: 0.4rem 1rem;
        border-radius: 20px;
        font-size: 0.8rem;
        font-weight: 700;
        color: #ffffff;
        box-shadow: 0 2px 4px rgba(0,0,0,0.2);
    }
    
    .source-badge-web {
        background: #1976d2;
    }
    
    .source-badge-local {
        background: #388e3c;
    }
    
    /* Progress indicator */
    .progress-indicator {
        text-align: center;
        padding: 1rem;
        font-size: 1.1rem;
        font-weight: 600;
        color: #667eea;
        animation: fade-in 0.5s;
    }
    
    @keyframes fade-in {
        from { opacity: 0; }
        to { opacity: 1; }
    }
    
    /* ANSWER BOX - PERFECT READABILITY */
    .answer-box {
        background-color: #f8f9fa;
        color: #212529;
        padding: 2.5rem;
        border-radius: 15px;
        border: 3px solid #667eea;
        box-shadow: 0 6px 20px rgba(102, 126, 234, 0.15);
        font-size: 1.15rem;
        line-height: 2;
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', sans-serif;
        margin: 1.5rem 0;
    }
    
    .answer-box strong {
        color: #495057;
    }
    
    .answer-box em {
        color: #6c757d;
    }
</style>
""", unsafe_allow_html=True)

# ==================== SESSION STATE ====================
if 'pipeline' not in st.session_state:
    st.session_state.pipeline = None
    st.session_state.initialized = False
    st.session_state.query_history = []

# ==================== HEADER ====================
st.markdown('<h1 class="main-header">üß† ContextWeaver</h1>', unsafe_allow_html=True)
st.markdown('<p class="sub-header">Next-Generation Multi-Document Reasoning with Hybrid Intelligence</p>', unsafe_allow_html=True)

# Component showcase
st.markdown("""
<div style="text-align: center; margin-bottom: 2.5rem;">
    <span class="component-badge">üóÑÔ∏è Advanced RAG</span>
    <span class="component-badge">‚úçÔ∏è Prompt Engineering</span>
    <span class="component-badge">üß¨ Synthetic Data</span>
    <span class="innovation-badge">üï∏Ô∏è Knowledge Graph</span>
    <span class="innovation-badge">üé≤ Uncertainty AI</span>
    <span class="innovation-badge">‚úÖ Fact-Checking</span>
    <span class="innovation-badge">üåê Hybrid Retrieval</span>
</div>
""", unsafe_allow_html=True)

# ==================== SIDEBAR ====================
with st.sidebar:
    st.header("‚öôÔ∏è System Control")
    
    if not st.session_state.initialized:
        if st.button("üöÄ Initialize ContextWeaver", type="primary", use_container_width=True):
            with st.spinner("Initializing all 11 modules..."):
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                try:
                    status_text.text("‚öôÔ∏è Loading core modules...")
                    progress_bar.progress(15)
                    time.sleep(0.3)
                    
                    status_text.text("üß† Initializing AI components...")
                    st.session_state.pipeline = ContextWeaverPipeline(use_existing_db=False)
                    progress_bar.progress(40)
                    time.sleep(0.3)
                    
                    status_text.text("üìö Processing documents...")
                    sample_files = list(Config.SAMPLE_DOCS_DIR.glob("*.txt"))
                    
                    if sample_files:
                        progress_bar.progress(60)
                        
                        status_text.text("üóÑÔ∏è Creating vector embeddings...")
                        report = st.session_state.pipeline.ingest_documents([str(f) for f in sample_files])
                        progress_bar.progress(85)
                        time.sleep(0.2)
                        
                        status_text.text("üï∏Ô∏è Building knowledge graph...")
                        progress_bar.progress(100)
                        time.sleep(0.2)
                        
                        st.session_state.initialized = True
                        
                        status_text.empty()
                        progress_bar.empty()
                        
                        st.success(f"""‚úÖ **Initialization Complete!**
                        
üìä **System Ready:**
- Vector Chunks: {report['chunks_created']}
- Graph Nodes: {report['graph_stats']['num_nodes']}
- Graph Edges: {report['graph_stats']['num_edges']}
- Contradictions Found: {report['contradictions_found']}
                        """)
                        st.balloons()
                    
                except Exception as e:
                    status_text.empty()
                    progress_bar.empty()
                    st.error(f"‚ùå Initialization failed: {e}")
    else:
        if st.button("üîÑ Reset System", use_container_width=True):
            st.session_state.clear()
            st.rerun()
    
    st.divider()
    
    # System stats
    if st.session_state.initialized:
        st.header("üìä Live System Stats")
        
        stats = st.session_state.pipeline.get_system_statistics()
        
        st.metric("üóÑÔ∏è Vector Chunks", stats['vector_store'].get('total_chunks', 0))
        st.metric("üìö Documents", stats['knowledge_base'].get('total_documents', 0))
        st.metric("üï∏Ô∏è Graph Nodes", stats['document_graph'].get('num_nodes', 0))
        st.metric("üîó Graph Edges", stats['document_graph'].get('num_edges', 0))
        
        if stats['knowledge_base'].get('coverage_score'):
            coverage = stats['knowledge_base']['coverage_score']
            st.progress(coverage, text=f"KB Coverage: {coverage:.0%}")
    
    st.divider()
    
    # Component controls
    st.header("üéõÔ∏è Component Controls")
    
    enable_multi_hop = st.toggle("üß† Multi-Hop Reasoning", value=True, help="Reason across multiple documents")
    enable_contradictions = st.toggle("‚ö†Ô∏è Contradiction Detection", value=True, help="Find conflicting information")
    enable_uncertainty = st.toggle("üé≤ Uncertainty Quantification", value=True, help="Bayesian confidence estimation")
    enable_fact_check = st.toggle("‚úÖ Fact-Checking", value=True, help="Verify claims against sources")
    
    st.divider()
    
    # Show enabled components count
    enabled_count = sum([enable_multi_hop, enable_contradictions, enable_uncertainty, enable_fact_check])
    st.info(f"**{enabled_count + 2}/6** components enabled\n(RAG & Hybrid Retrieval always active)")

# ==================== MAIN CONTENT ====================

if not st.session_state.initialized:
    st.info("üëà **Click 'Initialize ContextWeaver' in the sidebar to start**")
    
    # Feature overview
    st.header("üåü What Makes ContextWeaver Special?")
    
    feature_col1, feature_col2, feature_col3 = st.columns(3)
    
    with feature_col1:
        st.markdown("""
        #### üéØ Core Components
        **1. RAG System**
        - Knowledge base organization
        - Vector storage (ChromaDB)
        - 4 chunking strategies
        - Multi-factor ranking
        
        **2. Prompt Engineering**
        - 8 systematic templates
        - Few-shot learning
        - Context management
        - Edge case handling
        
        **3. Synthetic Data**
        - Q&A pair generation
        - Data augmentation
        - Quality: 94.4%
        - Diversity: 70.7%
        """)
    
    with feature_col2:
        st.markdown("""
        #### üåü Major Innovations
        **1. Knowledge Graph**
        - PageRank importance
        - Relationship detection
        - Graph traversal
        - Interactive visualization
        
        **2. Uncertainty Quantification**
        - Bayesian confidence
        - Sensitivity analysis
        - Evidence gap detection
        - Confidence calibration
        """)
    
    with feature_col3:
        st.markdown("""
        #### ‚ö° Advanced Features
        **3. Automated Fact-Checking**
        - Claim extraction
        - Multi-source verification
        - Red flag detection
        - Misinformation risk scoring
        
        **4. Hybrid Retrieval**
        - Tier 1: Local knowledge base
        - Tier 2: Web search fallback
        - Tier 3: LLM direct knowledge
        - **Handles ANY query!**
        """)

else:
    # Query interface
    st.header("üîç Intelligent Query Interface")
    
    query = st.text_input(
        "Enter your question:",
        placeholder="Ask anything! ContextWeaver will find the best source automatically...",
        help="Local KB for uploaded docs, Web search for other topics, LLM as last resort"
    )
    
    if query:
        st.caption(f"üìù Query length: {len(query)} characters | {len(query.split())} words")
    
    # Example queries - categorized
    st.write("**üí° Try These Examples:**")
    
    example_col1, example_col2 = st.columns(2)
    
    with example_col1:
        st.write("*üìö Local Knowledge Base (Coffee Research):*")
        if st.button("‚òï Coffee Safety", use_container_width=True):
            query = "Is moderate coffee consumption safe for heart health?"
        if st.button("‚ö†Ô∏è Research Contradictions", use_container_width=True):
            query = "What contradictions exist in coffee and heart health research?"
        if st.button("üìÖ Knowledge Evolution", use_container_width=True):
            query = "How has understanding of coffee evolved from 2018 to 2023?"
    
    with example_col2:
        st.write("*üåê Web Search Fallback (Any Topic):*")
        if st.button("üçó Chicken & Heart Health", use_container_width=True):
            query = "Is chicken meat good for heart health?"
        if st.button("üèÉ Exercise Benefits", use_container_width=True):
            query = "What are the cardiovascular benefits of regular exercise?"
        if st.button("ü•ó Mediterranean Diet", use_container_width=True):
            query = "Is the Mediterranean diet beneficial for preventing heart disease?"
    
    # Main analyze button
    if st.button("üöÄ Analyze with Full ContextWeaver Pipeline", type="primary", use_container_width=True) and query:
        
        # ===== LIVE PIPELINE VISUALIZATION =====
        st.divider()
        st.header("üîÑ Live Pipeline Execution")
        
        # Create pipeline status placeholders
        pipeline_container = st.container()
        
        with pipeline_container:
            # Define all pipeline steps
            pipeline_steps = [
                ("validate", "1Ô∏è‚É£ Query Validation", True),
                ("retrieve", "2Ô∏è‚É£ Hybrid Retrieval (Local‚ÜíWeb‚ÜíLLM)", True),
                ("rerank", "3Ô∏è‚É£ Document Re-Ranking", True),
                ("multi_hop", "4Ô∏è‚É£ Multi-Hop Reasoning", enable_multi_hop),
                ("contradictions", "5Ô∏è‚É£ Contradiction Detection", enable_contradictions),
                ("uncertainty", "6Ô∏è‚É£ Uncertainty Quantification", enable_uncertainty),
                ("fact_check", "7Ô∏è‚É£ Fact-Checking", enable_fact_check),
                ("compile", "8Ô∏è‚É£ Result Compilation", True),
            ]
            
            # Create placeholder for each step
            step_placeholders = {}
            for step_id, step_name, is_enabled in pipeline_steps:
                step_placeholders[step_id] = st.empty()
                
                # Initial state
                if is_enabled:
                    step_placeholders[step_id].markdown(f'<div class="pipeline-step pending">‚è≥ {step_name}</div>', unsafe_allow_html=True)
                else:
                    step_placeholders[step_id].markdown(f'<div class="pipeline-step disabled">‚è∏Ô∏è {step_name} (Disabled)</div>', unsafe_allow_html=True)
        
        # Progress tracker
        progress_text = st.empty()
        overall_progress = st.progress(0)
        
        try:
            # Step 1: Validation
            step_placeholders['validate'].markdown('<div class="pipeline-step processing">‚ö° 1Ô∏è‚É£ Query Validation - PROCESSING...</div>', unsafe_allow_html=True)
            progress_text.markdown('<p class="progress-indicator">üîç Validating query structure...</p>', unsafe_allow_html=True)
            time.sleep(0.5)
            overall_progress.progress(10)
            
            step_placeholders['validate'].markdown('<div class="pipeline-step complete">‚úÖ 1Ô∏è‚É£ Query Validation - COMPLETE</div>', unsafe_allow_html=True)
            
            # Step 2: Retrieval
            step_placeholders['retrieve'].markdown('<div class="pipeline-step processing">‚ö° 2Ô∏è‚É£ Hybrid Retrieval - PROCESSING...</div>', unsafe_allow_html=True)
            progress_text.markdown('<p class="progress-indicator">üîÑ Searching local KB ‚Üí Web ‚Üí LLM...</p>', unsafe_allow_html=True)
            time.sleep(0.3)
            overall_progress.progress(20)
            
            # Actual query execution
            result = st.session_state.pipeline.query(
                query,
                enable_multi_hop=enable_multi_hop,
                enable_contradiction_detection=enable_contradictions,
                enable_uncertainty=enable_uncertainty,
                enable_fact_checking=enable_fact_check
            )
            
            retrieval_source = result['retrieval']['retrieval_source']
            step_placeholders['retrieve'].markdown(f'<div class="pipeline-step complete">‚úÖ 2Ô∏è‚É£ Hybrid Retrieval - COMPLETE (Source: {retrieval_source.upper()})</div>', unsafe_allow_html=True)
            overall_progress.progress(30)
            
            # Step 3: Re-ranking
            step_placeholders['rerank'].markdown('<div class="pipeline-step processing">‚ö° 3Ô∏è‚É£ Document Re-Ranking - PROCESSING...</div>', unsafe_allow_html=True)
            progress_text.markdown('<p class="progress-indicator">üìä Applying multi-factor scoring...</p>', unsafe_allow_html=True)
            time.sleep(0.4)
            step_placeholders['rerank'].markdown('<div class="pipeline-step complete">‚úÖ 3Ô∏è‚É£ Document Re-Ranking - COMPLETE</div>', unsafe_allow_html=True)
            overall_progress.progress(40)
            
            # Step 4: Multi-hop
            if enable_multi_hop:
                step_placeholders['multi_hop'].markdown('<div class="pipeline-step processing">‚ö° 4Ô∏è‚É£ Multi-Hop Reasoning - PROCESSING...</div>', unsafe_allow_html=True)
                progress_text.markdown('<p class="progress-indicator">üß† Reasoning across documents...</p>', unsafe_allow_html=True)
                time.sleep(0.5)
                
                if result.get('reasoning'):
                    hops = result['reasoning']['hops_used']
                    step_placeholders['multi_hop'].markdown(f'<div class="pipeline-step complete">‚úÖ 4Ô∏è‚É£ Multi-Hop Reasoning - COMPLETE ({hops} hops)</div>', unsafe_allow_html=True)
                else:
                    step_placeholders['multi_hop'].markdown('<div class="pipeline-step complete">‚úÖ 4Ô∏è‚É£ Multi-Hop Reasoning - SKIPPED</div>', unsafe_allow_html=True)
            
            overall_progress.progress(55)
            
            # Step 5: Contradictions
            if enable_contradictions:
                step_placeholders['contradictions'].markdown('<div class="pipeline-step processing">‚ö° 5Ô∏è‚É£ Contradiction Detection - PROCESSING...</div>', unsafe_allow_html=True)
                progress_text.markdown('<p class="progress-indicator">üîç Analyzing for conflicts...</p>', unsafe_allow_html=True)
                time.sleep(0.4)
                
                if result.get('contradictions'):
                    num_c = result['contradictions'].get('num_contradictions', 0)
                    step_placeholders['contradictions'].markdown(f'<div class="pipeline-step complete">‚úÖ 5Ô∏è‚É£ Contradiction Detection - COMPLETE ({num_c} found)</div>', unsafe_allow_html=True)
                else:
                    step_placeholders['contradictions'].markdown('<div class="pipeline-step complete">‚úÖ 5Ô∏è‚É£ Contradiction Detection - SKIPPED</div>', unsafe_allow_html=True)
            
            overall_progress.progress(70)
            
            # Step 6: Uncertainty
            if enable_uncertainty:
                step_placeholders['uncertainty'].markdown('<div class="pipeline-step processing">‚ö° 6Ô∏è‚É£ Uncertainty Quantification - PROCESSING...</div>', unsafe_allow_html=True)
                progress_text.markdown('<p class="progress-indicator">üé≤ Computing Bayesian confidence...</p>', unsafe_allow_html=True)
                time.sleep(0.4)
                
                if result.get('uncertainty'):
                    conf = result['uncertainty']['confidence_score']
                    step_placeholders['uncertainty'].markdown(f'<div class="pipeline-step complete">‚úÖ 6Ô∏è‚É£ Uncertainty Quantification - COMPLETE ({conf:.0%} confidence)</div>', unsafe_allow_html=True)
                else:
                    step_placeholders['uncertainty'].markdown('<div class="pipeline-step complete">‚úÖ 6Ô∏è‚É£ Uncertainty Quantification - SKIPPED</div>', unsafe_allow_html=True)
            
            overall_progress.progress(85)
            
            # Step 7: Fact-check
            if enable_fact_check:
                step_placeholders['fact_check'].markdown('<div class="pipeline-step processing">‚ö° 7Ô∏è‚É£ Fact-Checking - PROCESSING...</div>', unsafe_allow_html=True)
                progress_text.markdown('<p class="progress-indicator">‚úÖ Verifying claims...</p>', unsafe_allow_html=True)
                time.sleep(0.4)
                
                if result.get('fact_check'):
                    fc_score = result['fact_check']['overall_score']
                    step_placeholders['fact_check'].markdown(f'<div class="pipeline-step complete">‚úÖ 7Ô∏è‚É£ Fact-Checking - COMPLETE ({fc_score:.0%} verified)</div>', unsafe_allow_html=True)
                else:
                    step_placeholders['fact_check'].markdown('<div class="pipeline-step complete">‚úÖ 7Ô∏è‚É£ Fact-Checking - SKIPPED</div>', unsafe_allow_html=True)
            
            overall_progress.progress(95)
            
            # Step 8: Compile
            step_placeholders['compile'].markdown('<div class="pipeline-step processing">‚ö° 8Ô∏è‚É£ Result Compilation - PROCESSING...</div>', unsafe_allow_html=True)
            progress_text.markdown('<p class="progress-indicator">üìä Generating comprehensive report...</p>', unsafe_allow_html=True)
            time.sleep(0.3)
            step_placeholders['compile'].markdown('<div class="pipeline-step complete">‚úÖ 8Ô∏è‚É£ Result Compilation - COMPLETE</div>', unsafe_allow_html=True)
            overall_progress.progress(100)
            
            progress_text.empty()
            time.sleep(0.5)
            overall_progress.empty()
            
            # Success message
            st.success("üéâ **Pipeline execution complete!** All enabled components processed successfully.")
            
            # Store result
            st.session_state.query_history.append({
                'query': query,
                'result': result,
                'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            })
            
            st.divider()
            
            # ===== RETRIEVAL SOURCE DISPLAY =====
            st.header("üì° Retrieval & Source Analysis")
            
            source = result['retrieval']['retrieval_source']
            
            source_configs = {
                'local': ('source-local', 'üìö', 'Local Knowledge Base', 'Retrieved from your uploaded documents'),
                'web': ('source-web', 'üåê', 'Web Search Results', 'Information found via web search'),
                'hybrid_local_web': ('source-web', 'üîÑ', 'Hybrid (Local + Web)', 'Combined local documents with web results'),
                'llm_direct': ('source-llm', 'ü§ñ', 'AI Direct Knowledge', 'Generated from LLM training knowledge')
            }
            
            css_class, icon, name, description = source_configs.get(source, source_configs['local'])
            
            st.markdown(f"""
            <div class="{css_class}">
                <h2>{icon} Retrieval Source: {name}</h2>
                <p style="font-size: 1.1rem;">{description}</p>
                <p style="font-size: 1.05rem; margin-top: 0.8rem;"><strong>Retrieval Confidence:</strong> {result['retrieval']['retrieval_confidence']:.0%}</p>
            </div>
            """, unsafe_allow_html=True)
            
            # Detailed retrieval metrics
            metric_col1, metric_col2, metric_col3, metric_col4, metric_col5 = st.columns(5)
            
            with metric_col1:
                web_count = result['retrieval'].get('web_results_used', 0)
                st.metric("üåê Web Results", web_count, help="Documents from web search")
            
            with metric_col2:
                local_count = result['retrieval'].get('local_results_used', 0)
                st.metric("üìö Local Results", local_count, help="Documents from local knowledge base")
            
            with metric_col3:
                st.metric("üìä Total Documents", result['retrieval']['num_documents'], help="All documents analyzed")
            
            with metric_col4:
                fallback_text = "‚úÖ Yes" if result['retrieval'].get('fallback_used') else "‚ùå No"
                st.metric("üîÑ Fallback Used", fallback_text, help="Whether fallback to web/LLM was needed")
            
            with metric_col5:
                conf_pct = result['retrieval']['retrieval_confidence']
                st.metric("üéØ Ret. Confidence", f"{conf_pct:.0%}", help="Confidence in retrieval quality")
            
            # Display sources
            with st.expander("üìö Top Sources Analyzed (Click to expand)", expanded=True):
                st.write("**Sources used for this answer:**")
                
                for i, source_name in enumerate(result['retrieval']['top_sources'][:5], 1):
                    # Detect web vs local source
                    web_keywords = ['Harvard', 'WebMD', 'Mayo', 'Cleveland', 'American', 'Journal', 'Clinic', 'Nutrition', 'Health', 'Medical']
                    is_web_source = any(kw in str(source_name) for kw in web_keywords)
                    
                    if is_web_source:
                        st.markdown(f"""
                        <div class="source-item-web">
                            <span style="font-size: 1.3rem;">üåê</span>
                            <strong style="font-size: 1.05rem;">{i}. {source_name}</strong>
                            <span class="source-badge source-badge-web">WEB</span>
                        </div>
                        """, unsafe_allow_html=True)
                    else:
                        st.markdown(f"""
                        <div class="source-item-local">
                            <span style="font-size: 1.3rem;">üìÑ</span>
                            <strong style="font-size: 1.05rem;">{i}. {source_name}</strong>
                            <span class="source-badge source-badge-local">LOCAL</span>
                        </div>
                        """, unsafe_allow_html=True)
            
            st.divider()
            
            # ===== ANSWER SECTION - FIXED FOR PERFECT READABILITY =====
            st.header("üí° Generated Answer")
            
            # Get clean answer without source indicators
            raw_answer = result.get('raw_answer', result['answer'])
            
            # Display in perfectly readable box
            st.markdown(f"""
            <div class="answer-box">
                {raw_answer}
            </div>
            """, unsafe_allow_html=True)
            
            # Show source indicator as separate badge below answer
            source_badge_configs = {
                'local': ('üìö Local Knowledge Base', '#28a745', 'Highest confidence - from your documents'),
                'web': ('üåê Web Search', '#1976d2', 'Medium confidence - verify independently'),
                'hybrid_local_web': ('üîÑ Hybrid Sources', '#1976d2', 'Combined local and web sources'),
                'llm_direct': ('ü§ñ AI Knowledge', '#f57c00', 'Lower confidence - LLM training data only')
            }
            
            badge_text, badge_color, badge_help = source_badge_configs.get(source, source_badge_configs['local'])
            
            st.markdown(f"""
            <div style="text-align: center; margin-top: 1rem;">
                <span style="background: {badge_color}; color: white; padding: 0.6rem 1.5rem; border-radius: 20px; font-weight: 600; font-size: 1rem; box-shadow: 0 2px 8px rgba(0,0,0,0.15);">
                    {badge_text}
                </span>
                <p style="color: #6c757d; font-size: 0.9rem; margin-top: 0.5rem;">{badge_help}</p>
            </div>
            """, unsafe_allow_html=True)
            
            st.divider()
            
            # ===== KEY METRICS DASHBOARD =====
            st.header("üìä Analysis Metrics Dashboard")
            
            metric_col1, metric_col2, metric_col3, metric_col4 = st.columns(4)
            
            with metric_col1:
                if result.get('reasoning'):
                    hops = result['reasoning']['hops_used']
                    reasoning_conf = result['reasoning']['confidence']
                    conf_color = '#28a745' if reasoning_conf >= 0.7 else '#ffc107' if reasoning_conf >= 0.5 else '#dc3545'
                    
                    st.markdown(f"""
                    <div class="metric-card">
                        <h4>üß† Multi-Hop Reasoning</h4>
                        <p style="font-size: 2.8rem; font-weight: 700; margin: 0.8rem 0; color: #667eea;">{hops}</p>
                        <p style="font-size: 1.1rem; color: #5a6c7d;">reasoning hops</p>
                        <p style="margin-top: 1rem; font-size: 1.05rem; color: #2c3e50;"><strong>Confidence:</strong> <span style="color: {conf_color};">{reasoning_conf:.0%}</span></p>
                    </div>
                    """, unsafe_allow_html=True)
                else:
                    st.info("üß† **Multi-Hop**\nNot activated")
            
            with metric_col2:
                if result.get('uncertainty'):
                    conf_score = result['uncertainty']['confidence_score']
                    level = result['uncertainty']['confidence_level']
                    conf_color = '#28a745' if conf_score >= 0.7 else '#ffc107' if conf_score >= 0.5 else '#dc3545'
                    
                    st.markdown(f"""
                    <div class="metric-card">
                        <h4>üé≤ Uncertainty</h4>
                        <p style="font-size: 2.8rem; font-weight: 700; margin: 0.8rem 0; color: {conf_color};">{conf_score:.0%}</p>
                        <p style="font-size: 1.1rem; color: #5a6c7d;">{level}</p>
                    </div>
                    """, unsafe_allow_html=True)
                else:
                    st.info("üé≤ **Uncertainty**\nNot activated")
            
            with metric_col3:
                if result.get('fact_check'):
                    fc_score = result['fact_check']['overall_score']
                    fc_level = result['fact_check']['verification_level']
                    fc_color = '#28a745' if fc_score >= 0.7 else '#ffc107' if fc_score >= 0.5 else '#dc3545'
                    
                    st.markdown(f"""
                    <div class="metric-card">
                        <h4>‚úÖ Fact-Check</h4>
                        <p style="font-size: 2.8rem; font-weight: 700; margin: 0.8rem 0; color: {fc_color};">{fc_score:.0%}</p>
                        <p style="font-size: 1.1rem; color: #5a6c7d;">{fc_level}</p>
                        <p style="margin-top: 1rem; font-size: 1.05rem; color: #2c3e50;"><strong>Verified:</strong> {result['fact_check']['num_verified']}/{len(result['fact_check']['claims'])}</p>
                    </div>
                    """, unsafe_allow_html=True)
                else:
                    st.info("‚úÖ **Fact-Check**\nNot activated")
            
            with metric_col4:
                if result.get('contradictions'):
                    num_c = result['contradictions'].get('num_contradictions', 0)
                    severity = result['contradictions'].get('overall_severity', 'NONE')
                    sev_colors = {'HIGH': '#dc3545', 'MEDIUM': '#ffc107', 'LOW': '#28a745', 'NONE': '#6c757d'}
                    sev_color = sev_colors.get(severity, '#6c757d')
                    
                    st.markdown(f"""
                    <div class="metric-card">
                        <h4>‚ö†Ô∏è Contradictions</h4>
                        <p style="font-size: 2.8rem; font-weight: 700; margin: 0.8rem 0; color: {sev_color};">{num_c}</p>
                        <p style="font-size: 1.1rem; color: #5a6c7d;">{severity} severity</p>
                    </div>
                    """, unsafe_allow_html=True)
                else:
                    st.success("‚ö†Ô∏è **None**")
            
            st.divider()
            
            # ===== DETAILED ANALYSIS TABS =====
            st.header("üî¨ Detailed Component Analysis")
            
            detail_tabs = st.tabs([
                "üß† Reasoning Chain",
                "‚ö†Ô∏è Contradictions",
                "üé≤ Uncertainty",
                "‚úÖ Fact-Check",
                "üì¶ Module Manifest"
            ])
            
            # Tab 1: Reasoning
            with detail_tabs[0]:
                if result.get('reasoning'):
                    st.markdown(f"""
                    **üìä Reasoning Summary:**
                    - Hops Used: **{result['reasoning']['hops_used']}**
                    - Documents Analyzed: **{result['reasoning']['documents_used']}**
                    - Final Confidence: **{result['reasoning']['confidence']:.0%}**
                    """)
                    
                    st.markdown("---")
                    
                    for step in result['reasoning']['reasoning_chain']:
                        hop_num = step['hop_number']
                        
                        with st.expander(f"üîó Reasoning Hop {hop_num}/{result['reasoning']['hops_used']}", expanded=(hop_num <= 2)):
                            st.markdown("**üìù Information Extracted:**")
                            st.success(str(step.get('extracted_info', 'N/A')))
                            
                            st.markdown("**üîó Connection to Previous Context:**")
                            st.info(str(step.get('connection_to_context', 'N/A')))
                            
                            st.markdown("**üí° Intermediate Conclusion:**")
                            st.warning(str(step.get('intermediate_conclusion', 'N/A')))
                            
                            if step.get('documents_used'):
                                st.markdown("**üìö Documents Referenced:**")
                                for doc in step['documents_used']:
                                    st.write(f"‚Ä¢ {doc}")
                else:
                    st.info("üß† Multi-hop reasoning component was not activated for this query")
            
            # Tab 2: Contradictions
            with detail_tabs[1]:
                if result.get('contradictions') and result['contradictions'].get('contradictions'):
                    st.subheader(f"‚ö†Ô∏è Detected {result['contradictions']['num_contradictions']} Contradictions")
                    st.warning(f"**Overall Severity:** {result['contradictions']['overall_severity']}")
                    
                    for i, c in enumerate(result['contradictions']['contradictions'], 1):
                        severity = c.get('severity', 'MEDIUM')
                        severity_emoji = {'HIGH': 'üî¥', 'MEDIUM': 'üü°', 'LOW': 'üü¢'}.get(severity, '‚ö™')
                        
                        with st.expander(f"{severity_emoji} Contradiction #{i} - {severity} Severity", expanded=True):
                            col_a, col_b = st.columns(2)
                            
                            with col_a:
                                st.markdown("**üìç Claim A:**")
                                st.error(c.get('claim_A', 'N/A'))
                                st.caption(f"üìÑ Source: {c.get('source_A', 'N/A')}")
                            
                            with col_b:
                                st.markdown("**üìç Claim B:**")
                                st.error(c.get('claim_B', 'N/A'))
                                st.caption(f"üìÑ Source: {c.get('source_B', 'N/A')}")
                            
                            st.markdown("---")
                            st.markdown("**üîç Why They Contradict:**")
                            st.info(c.get('explanation', 'N/A'))
                            
                            st.metric("Detection Confidence", f"{c.get('confidence', 0):.0%}")
                else:
                    st.success("‚úÖ **No contradictions detected**")
                    st.write("This indicates consistency across all analyzed sources!")
            
            # Tab 3: Uncertainty
            with detail_tabs[2]:
                if result.get('uncertainty'):
                    unc = result['uncertainty']
                    conf_score = unc['confidence_score']
                    
                    # Interactive gauge
                    fig = go.Figure(go.Indicator(
                        mode="gauge+number+delta",
                        value=conf_score * 100,
                        title={'text': "Overall Confidence Score", 'font': {'size': 22}},
                        delta={'reference': 70, 'increasing': {'color': "green"}},
                        gauge={
                            'axis': {'range': [0, 100], 'tickwidth': 2},
                            'bar': {'color': "darkblue", 'thickness': 0.7},
                            'bgcolor': "white",
                            'steps': [
                                {'range': [0, 30], 'color': "#ffcccc"},
                                {'range': [30, 50], 'color': "#fff3cd"},
                                {'range': [50, 70], 'color': "#d1ecf1"},
                                {'range': [70, 100], 'color': "#d4edda"}
                            ],
                            'threshold': {
                                'line': {'color': "red", 'width': 4},
                                'thickness': 0.75,
                                'value': 50
                            }
                        }
                    ))
                    
                    fig.update_layout(height=350)
                    st.plotly_chart(fig, use_container_width=True)
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.markdown("**üìä Component Scores:**")
                        for component, score in unc.get('component_scores', {}).items():
                            st.progress(score, text=f"{component.replace('_', ' ').title()}: {score:.0%}")
                    
                    with col2:
                        st.markdown("**‚ö†Ô∏è Uncertainty Sources:**")
                        for j, source_text in enumerate(unc['uncertainty_sources'], 1):
                            st.warning(f"{j}. {source_text}")
                    
                    st.markdown("---")
                    st.markdown("**üìâ Evidence Gaps:**")
                    for gap in unc['evidence_gaps']:
                        st.info(f"‚Ä¢ {gap}")
                    
                    # Sensitivity analysis
                    if unc.get('sensitivity_analysis'):
                        st.markdown("---")
                        st.markdown("**üî¨ Sensitivity Analysis - What-If Scenarios:**")
                        
                        for scenario, new_conf in unc['sensitivity_analysis'].items():
                            change = new_conf - conf_score
                            delta_str = f"+{change:.1%}" if change > 0 else f"{change:.1%}"
                            
                            col_s1, col_s2 = st.columns([3, 1])
                            with col_s1:
                                st.write(f"**{scenario.replace('_', ' ').title()}**")
                            with col_s2:
                                st.metric("", f"{new_conf:.0%}", delta_str)
                else:
                    st.info("üé≤ Uncertainty quantification component was not activated")
            
            # Tab 4: Fact-Check
            with detail_tabs[3]:
                if result.get('fact_check'):
                    fc = result['fact_check']
                    
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.metric("Overall Verification", f"{fc['overall_score']:.0%}", fc['verification_level'])
                    with col2:
                        st.metric("‚úÖ Verified Claims", f"{fc['num_verified']}/{len(fc['claims'])}")
                    with col3:
                        st.metric("üö® Red Flags", len(result.get('red_flags', [])))
                    
                    st.markdown("---")
                    st.markdown("**üîç Individual Claim Verification:**")
                    
                    for i, verification in enumerate(fc['verifications'], 1):
                        status = verification['status']
                        
                        status_configs = {
                            'VERIFIED': ('‚úÖ', '#d4edda', '#155724'),
                            'UNSUPPORTED': ('‚ö†Ô∏è', '#fff3cd', '#856404'),
                            'CONTRADICTED': ('‚ùå', '#f8d7da', '#721c24'),
                            'UNCERTAIN': ('‚ùì', '#d1ecf1', '#004085')
                        }
                        
                        icon, bg_color, text_color = status_configs.get(status, ('‚ùì', '#e2e3e5', '#383d41'))
                        
                        st.markdown(f"""
                        <div style="background: {bg_color}; padding: 1.2rem; border-radius: 10px; margin: 0.6rem 0; border-left: 4px solid {text_color};">
                            <p style="margin: 0; color: {text_color}; font-size: 1.05rem;">
                                <strong>{icon} Claim {i}:</strong> {verification['claim']}
                            </p>
                            <p style="margin: 0.6rem 0 0 0; font-size: 0.95rem; color: {text_color};">
                                <strong>Status:</strong> {status} | 
                                <strong>Confidence:</strong> {verification['confidence']:.0%}
                            </p>
                        </div>
                        """, unsafe_allow_html=True)
                    
                    # Red flags
                    if result.get('red_flags'):
                        st.markdown("---")
                        st.markdown("**üö® Red Flags Detected:**")
                        for flag in result['red_flags']:
                            st.error(f"""
                            **{flag['type'].replace('_', ' ').title()}** - {flag['severity']} Severity
                            
                            {flag['description']}
                            
                            üí° Recommendation: {flag.get('recommendation', 'Review carefully before trusting')}
                            """)
                else:
                    st.info("‚úÖ Fact-checking component was not activated")
            
            # Tab 5: Module Manifest
            with detail_tabs[4]:
                st.markdown("### üì¶ Complete System Architecture")
                
                st.markdown("""
                **‚úÖ Core Components (3/3 Required - 150% Achievement!):**
                
                1. **üóÑÔ∏è RAG System**
                   - `document_processor.py`, `vector_store.py`
                   - Knowledge base, vector embeddings, 4 chunking strategies, multi-factor ranking
                
                2. **‚úçÔ∏è Prompt Engineering**
                   - `prompt_engineering.py`
                   - 8 templates, few-shot learning, context management, edge cases
                
                3. **üß¨ Synthetic Data Generation**
                   - `synthetic_data_generator.py`
                   - Q&A pairs, augmentation, quality 94.4%, diversity 70.7%, ethics
                
                ---
                
                **üåü Advanced Innovations (4 Major Features):**
                
                1. **üï∏Ô∏è Knowledge Graph** - `document_graph.py`
                   - PageRank, relationships, graph traversal, visualization
                
                2. **üé≤ Uncertainty Quantification** - `uncertainty_quantification.py`
                   - Bayesian confidence, sensitivity analysis, evidence gaps
                
                3. **‚úÖ Automated Fact-Checking** - `fact_checker.py`
                   - Claim verification, red flags, misinformation risk scoring
                
                4. **üåê Hybrid Retrieval** - `web_search_fallback.py`
                   - 3-tier fallback (Local‚ÜíWeb‚ÜíLLM), intelligent routing
                
                ---
                
                **‚ö° Advanced Reasoning:** `reasoning_engine.py`
                - Multi-hop reasoning, contradictions, citations, temporal analysis
                
                **üîß Infrastructure:** `config.py`, `contextweaver_pipeline.py`
                
                **üìä Total: 11 modules, ~4,000+ lines of code**
                """)
            
            st.divider()
            
            # ===== EXPORT SECTION =====
            st.header("üíæ Export Analysis Results")
            
            export_col1, export_col2, export_col3 = st.columns(3)
            
            with export_col1:
                json_data = json.dumps(make_serializable(result), indent=2)
                st.download_button(
                    "üìÑ Download JSON",
                    json_data,
                    file_name=f"contextweaver_json_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                    mime="application/json",
                    use_container_width=True,
                    help="Complete analysis data in JSON format"
                )
            
            with export_col2:
                report = st.session_state.pipeline.generate_comprehensive_report(result)
                st.download_button(
                    "üìù Download Report",
                    report,
                    file_name=f"contextweaver_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                    mime="text/plain",
                    use_container_width=True,
                    help="Human-readable analysis report"
                )
            
            with export_col3:
                combined = f"""CONTEXTWEAVER ANALYSIS EXPORT
Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
Query: {query}

{'='*60}
ANALYSIS REPORT
{'='*60}

{report}

{'='*60}
JSON DATA
{'='*60}

{json_data}
"""
                st.download_button(
                    "üì¶ Complete Package",
                    combined,
                    file_name=f"contextweaver_complete_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                    mime="text/plain",
                    use_container_width=True,
                    help="Report + JSON in single file"
                )
            
        except Exception as e:
            st.error(f"‚ùå **Error During Pipeline Execution**")
            st.exception(e)

# ==================== QUERY HISTORY ====================
if st.session_state.query_history:
    with st.sidebar:
        st.divider()
        st.header("üìú Query History")
        st.caption(f"{len(st.session_state.query_history)} queries processed")
        
        for i, item in enumerate(reversed(st.session_state.query_history[-5:]), 1):
            with st.expander(f"{i}. {item['query'][:30]}...", expanded=False):
                st.caption(f"üïê {item['timestamp']}")
                st.caption(f"üìç Source: {item['result']['retrieval']['retrieval_source'].upper()}")
                
                if item['result'].get('uncertainty'):
                    conf = item['result']['uncertainty']['confidence_score']
                    st.progress(conf, text=f"Confidence: {conf:.0%}")

# ==================== FOOTER ====================
st.divider()
st.markdown("""
<div style="text-align: center; padding: 2.5rem; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; box-shadow: 0 8px 20px rgba(0,0,0,0.2);">
    <h2 style="color: #ffffff; margin-bottom: 1rem; font-size: 2.8rem; font-weight: 800;">üß† ContextWeaver</h2>
    <p style="color: #ffffff; font-size: 1.4rem; margin-bottom: 1rem; font-weight: 600;">Advanced Multi-Document Reasoning Engine</p>
    <p style="color: rgba(255,255,255,0.95); font-size: 1.1rem; margin-bottom: 0.5rem;">üìö 3 Core Components ‚Ä¢ üåü 4 Major Innovations ‚Ä¢ üß† 11 Integrated Modules</p>
    <p style="color: rgba(255,255,255,0.9); font-size: 1rem; margin-bottom: 0.3rem;">~4,000+ Lines of Code ‚Ä¢ Production-Ready Architecture</p>
    <p style="color: rgba(255,255,255,0.85); font-size: 0.95rem;">Hybrid Retrieval ‚Ä¢ Multi-Hop Reasoning ‚Ä¢ Uncertainty Quantification ‚Ä¢ Fact-Checking</p>
    <div style="margin-top: 2rem; padding-top: 1.5rem; border-top: 2px solid rgba(255,255,255,0.3);">
        <p style="color: #ffffff; font-size: 1.2rem; margin-bottom: 0.5rem; font-weight: 600;">INFO 7375 - Generative AI ‚Ä¢ Final Project</p>
        <p style="color: rgba(255,255,255,0.95); font-size: 1.05rem; margin-bottom: 1.5rem;">Northeastern University ‚Ä¢ Fall 2024</p>
        <p style="color: #ffffff; font-size: 1.3rem; font-weight: 700;">Sravan Kumar Kurapati</p>
    </div>
</div>
""", unsafe_allow_html=True)